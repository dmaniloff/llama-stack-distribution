<!-- This file is automatically generated by scripts/gen_distro_doc.py - do not update manually -->

# Open Data Hub Llama Stack Distribution Image

This image contains the official Open Data Hub Llama Stack distribution, with all the packages and configuration needed to run a Llama Stack server in a containerized environment.

The image is currently shipping with upstream Llama Stack version [0.2.22](https://github.com/llamastack/llama-stack/releases/tag/v0.2.22)

You can see an overview of the APIs and Providers the image ships with in the table below.

| API | Provider | Enabled by default? |
|-----|----------|---------------------|
| agents | inline::meta-reference | Yes |
| datasetio | inline::localfs | Yes |
| datasetio | remote::huggingface | Yes |
| eval | remote::trustyai_lmeval | Yes |
| files | inline::localfs | Yes |
| inference | inline::sentence-transformers | Yes |
| inference | remote::azure | No |
| inference | remote::bedrock | No |
| inference | remote::openai | No |
| inference | remote::vertexai | No |
| inference | remote::vllm | No |
| inference | remote::watsonx | No |
| safety | remote::trustyai_fms | Yes |
| scoring | inline::basic | Yes |
| scoring | inline::braintrust | Yes |
| scoring | inline::llm-as-judge | Yes |
| telemetry | inline::meta-reference | Yes |
| tool_runtime | inline::rag-runtime | Yes |
| tool_runtime | remote::brave-search | Yes |
| tool_runtime | remote::model-context-protocol | Yes |
| tool_runtime | remote::tavily-search | Yes |
| vector_io | inline::milvus | Yes |
| vector_io | remote::milvus | No |
